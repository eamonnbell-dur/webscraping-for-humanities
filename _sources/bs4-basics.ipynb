{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `bs4` Basics\n",
    "\n",
    "Here is an example of a very simple HTML document:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<html> \n",
    "  <head> \n",
    "    <title>My page</title> \n",
    "  </head> \n",
    "  <body> \n",
    "    <h2>Welcome to my <a href=\"https://example.com/index.html\">page</a></h2> \n",
    "    <p id=\"para1\" class=\"stylish small\">This is the first paragraph.</p> \n",
    "    <p id=\"para2\" class=\"unstylish small\">This is the second paragraph.</p> \n",
    "    <p id=\"para3\"> This is the third paragraph, which contains a <a href=\"https://example.com/about.html\">link</a> to another page.</p>\n",
    "    <!-- this is the end --> \n",
    "  </body> \n",
    "</html>\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we will learn to request arbitrary HTML documents from remote servers, store them to disk, and load them for analysis. But let's keep things simple and assign this document to a variable called `simple_doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_doc = \"\"\"<html> \n",
    "  <head> \n",
    "    <title>My page</title> \n",
    "  </head> \n",
    "  <body> \n",
    "    <h2>Welcome to my <a href=\"https://example.com/index.html\">page</a></h2> \n",
    "    <p id=\"para1\" class=\"stylish small\">This is the first paragraph.</p> \n",
    "    <p id=\"para2\" class=\"unstylish small\">This is the second paragraph.</p> \n",
    "    <p id=\"para3\"> This is the third paragraph, which contains a <a href=\"https://example.com/about.html\">link</a> to another page.</p>\n",
    "    <!-- this is the end --> \n",
    "  </body> \n",
    "</html>\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's we want to retrieve the title of this HTML document, which is stored in text, wrapped in the `<title>` tags. If you already know a bit about Python, you might know how to manipulate strings. Here, the document has been nicely formatted so that we could do something like this, using string methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<title>My page</title>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag = simple_doc.split('\\n')[2].strip()\n",
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My page'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_contents = title_tag.replace('<title>', '').replace('</title>', '')\n",
    "title_contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with this technique is that we are making too many assumptions about how the string that stores the HTML document is structured, for example, by assuming that the relevant tag is on the third line (`.split('\\n')[2]`) of the multi-line string. In fact, many HTML documents are structurally equivalent to each other, even if we remove all the line spacing. So there are no guarantees that the precis structure that we depend on above to identify the information we care about will be preserved in the form that the server provides us with the remote document. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better approach is to use Python to do the work of converting the string that stores the HTML document into an abstract representation of the tree structure that is the page's skeleton.\n",
    "\n",
    "In general, this step can be done precisely once for each HTML document, so that once it has been completed, we can start to use the features of the Python programming language to navigate the structure of the document - either manually, or, ultimately, programmatically.\n",
    "\n",
    "To do this, we use a third-party Python module called `BeautifulSoup`, which can be made available using the following `import` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask `bs4` to process the string that stores the HTML document and return a new Python object, that we will call `soup` throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = bs4.BeautifulSoup(simple_doc.replace('\\n', ''))\n",
    "type(soup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects of type `bs4.BeautifulSoup` support a wide range of methods that allow us to access elements of the HTML document. For example, the `.find()` method can be used to find the first instance of a tag with the name given in its first argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('title')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take care here. Even though the displayed representation of the object called `title` is the same as the HTML markup that generates it, it is not stored as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<title>My page</title>, bs4.element.Tag)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title, type(title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is, rather, a `bs4.element.Tag`, which supports methods useful for further manipulation, such as extracting the text attached to the `<title></title>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = title.get_text()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use methods on the `bs4.element.Tag` in order to retrieve elements that have a specific relationship to it within the HTML document, such as this method, which finds the parent of the element given: the `<head>` element. This method returns the whole subdocument enclosed by the relevant tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head> <title>My page</title> </head>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.findParent()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_next_sibling()` method can be used to find sibling elements, which are those at the same level in the document tree. They will be returned in the order that they appear in the document at that level. In this example, it is in the paragraph ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<p class=\"stylish small\" id=\"para1\">This is the first paragraph.</p>,\n",
       " 'This is the first paragraph.')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2_next_sibling = soup.body.h2.find_next_sibling()\n",
    "h2_next_sibling, h2_next_sibling.get_text()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_next_siblings()` method is a shortcut to return all siblings, which will be wrapped in a `ResultSet`, which behaves a little like a regular Python `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"unstylish small\" id=\"para2\">This is the second paragraph.</p>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2_next_siblings = soup.body.h2.find_next_siblings()\n",
    "h2_second_sibling = h2_next_siblings[1]\n",
    "h2_second_sibling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has consequences for how you might choose to manipulate the result. `bs4` provides a helpful message here to help you out of the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m h2_next_siblings\u001b[39m.\u001b[39;49mtext\n",
      "File \u001b[0;32m~/mambaforge/envs/webscraping-for-humanities/lib/python3.11/site-packages/bs4/element.py:2289\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   2288\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   2290\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mResultSet object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. You\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key\n\u001b[1;32m   2291\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "h2_next_siblings.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first paragraph.',\n",
       " 'This is the second paragraph.',\n",
       " ' This is the third paragraph, which contains a link to another page.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2_next_siblings_texts = [x.get_text() for x in h2_next_siblings]\n",
    "h2_next_siblings_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self-check 1**: \n",
    "\n",
    "Retrieve the text *content* of the three paragraph tags (`<p></p>`), place them in a Python list, and assign them to the variable `paragraph_texts`. You will need to read about the `.find_all()` method.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first paragraph.',\n",
       " 'This is the second paragraph.',\n",
       " ' This is the third paragraph, which contains a link to another page.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_texts = [p.get_text() for p in soup.find_all('p')]\n",
    "paragraph_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that this gives the same result as looking at the text attribute of `h2_next_siblings_texts`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(h2_next_siblings_texts == paragraph_texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's important to note is that the same result can be achieved by many different means: in the first instance, we arrive at the relevant `p` elements through their relative position with respect to the `h2` element that precedes them, whereas in the second example, we simply ask for all `p` elements in the document. \n",
    "\n",
    "Depending on your application, and depending on how frequently you expect the site you are scraping to change, different options will be appropriate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self-check 2**: \n",
    "\n",
    "Retrieve the link *destination* of all the hyperlinks in the document `<body`> and place them in a Python list, and assign them to the variable `document_links`. You will need to address the `href` attribute of each of the `<a>` elements you find.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://example.com/index.html', 'https://example.com/about.html']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_links = [a.attrs['href'] for a in soup.body.find_all('a')]\n",
    "document_links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The destination of hyperlinks is stored in the `href` attribute of a tag. There is often other useful information stored in the tag attributes. Specificially:\n",
    "\n",
    "- The `class` attribute contains information that is frequently used to modify the appearance of a HTML element in the browser (using a technology called CSS, which we do not need to deal with here)\n",
    "- The `id` attribute contains information that is frequently used to make a page interactive (using JavaScript and frontend frameworks), and to modify the appearance of a HTML element in the browser (using CSS)\n",
    "\n",
    "\n",
    "For example, the second paragraph tag contains some of this information:\n",
    "\n",
    "```html\n",
    "<p id=\"para1\" class=\"stylish small\">This is the first paragraph.</p> \n",
    "```\n",
    "\n",
    "- The `class` attribute contains two values, separated by a space: `stylish` and `small`. \n",
    "- The `id` attribute contains one value, `para1`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.find_all` with some additional arguments to use `bs4` to find tags in a parsed HTML document according to their attribute values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"stylish small\" id=\"para1\">This is the first paragraph.</p>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', id='para1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"unstylish small\" id=\"para2\">This is the second paragraph.</p>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', id='para2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you are trying to filter on the value of the element's `class` attribute, you will have to use the keyword argument `class_`, a naming decision made to avoid a clash with the reserved word `class`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3488578580.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    soup.find_all('p', class='small')\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "soup.find_all('p', class='small')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you search for a tag that matches a certain CSS class, youâ€™re matching against any of its CSS classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"stylish small\" id=\"para1\">This is the first paragraph.</p>,\n",
       " <p class=\"unstylish small\" id=\"para2\">This is the second paragraph.</p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='small')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also filter an attribute using a regular expression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"unstylish small\" id=\"para2\">This is the second paragraph.</p>,\n",
       " <p id=\"para3\"> This is the third paragraph, which contains a <a href=\"https://example.com/about.html\">link</a> to another page.</p>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "soup.find_all('p', id=re.compile('para[2-3]'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"stylish small\" id=\"para1\">This is the first paragraph.</p>,\n",
       " <p class=\"unstylish small\" id=\"para2\">This is the second paragraph.</p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_=['stylish', 'unstylish'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might like to keep all the information about the HTML document together, and one way to do this is to use a Python `dict`, which allows you to define record types. Let's say that for every HTML document we might scrape, we care about the following information:\n",
    "\n",
    "- The title of the document\n",
    "- The content of the first `h2` element in the document\n",
    "- The number of links the document contains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {\n",
    "    \"title_text\": soup.title.get_text(),\n",
    "    \"h2_text\" : soup.find('h2').get_text(),\n",
    "    \"num_links\" : len(soup.find_all('a'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title_text': 'My page', 'h2_text': 'Welcome to my page', 'num_links': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to tie all of the above into a short function that takes as its input a string storing a HTML document, parses the document using `bs4`, and returns a `dict` with the relevant information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record_for_document(html_doc):\n",
    "    soup = bs4.BeautifulSoup(html_doc)\n",
    "    record = {\n",
    "        \"title_text\": soup.title.get_text(),\n",
    "        \"h2_text\" : soup.find('h2').get_text(),\n",
    "        \"num_links\" : len(soup.find_all('a'))\n",
    "    }\n",
    "\n",
    "    return record"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define another simple HTML document. (Again, you will eventually retrieve these yourself from the web.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_simple_doc = \"\"\"<html> \n",
    "  <head> \n",
    "    <title>My other page</title> \n",
    "  </head> \n",
    "  <body> \n",
    "    <h2>Welcome to my <a href=\"https://example.com/index.html\">other page</a></h2> \n",
    "    <p id=\"para1\" class=\"stylish small\">This is the <a href=\"https://example.com/contact.html\">place you can contact me</a>.</p> \n",
    "    <p id=\"para2\"> This is the third paragraph, which contains a <a href=\"https://example.com/about.html\">link</a> to another page.</p>\n",
    "    <!-- this is the end --> \n",
    "  </body> \n",
    "</html>\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our function to produce a list of records from the documents we have to hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title_text': 'My page', 'h2_text': 'Welcome to my page', 'num_links': 2},\n",
       " {'title_text': 'My other page',\n",
       "  'h2_text': 'Welcome to my other page',\n",
       "  'num_links': 3}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = [get_record_for_document(simple_doc), get_record_for_document(another_simple_doc)]\n",
    "records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see the usefulness of using `dicts` to store record information, as it allows us to use Python's built-in `csv` library to store the records to disk in the plain-text comma-separated value (CSV) format, so that it may be consumed by other applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('bs4-basics-results.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=records[0].keys())\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_text,h2_text,num_links\n",
      "My page,Welcome to my page,2\n",
      "My other page,Welcome to my other page,3\n"
     ]
    }
   ],
   "source": [
    "!head bs4-basics-results.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping-for-humanities",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "790dd6c57fc929fd42e5ab267bfea63b216295e4d85fc21cf4d3027566e8b5a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
